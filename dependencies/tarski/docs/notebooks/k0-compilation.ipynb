{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# Solving Conformant Planning Problems with the $K_0$ Compilation\n",
    "\n",
    "For the purpose of this tutorial we will look at the seminal paper by Palacios and Geffner\n",
    "\"Compiling Uncertainty Away in Conformant Planning Problems with Bounded Width\", and see how\n",
    "we can implement the $K_0$ compilation of conformant into classical problems.\n",
    "\n",
    "*Definition* (Translation $K_0$). For a conformant planning problem $P=\\langle F,I,O,G\\rangle$, the \n",
    "translation $K_0(P) = \\langle F', I', O', G'\\rangle$ is classical planning problem with\n",
    " - $F' = \\{ KL, K\\neg L\\, \\mid\\, L \\in F \\}$\n",
    " - $I' = \\{ KL \\, \\mid \\, L \\text{ is a unit clause in } I\\}$\n",
    " - $G' = \\{ KL \\, \\mid \\, L \\in G\\}$\n",
    " - $O' = O$ but with each precondition $L$ for $a \\in O$ replaced by $KL$, and each conditional effect \n",
    " $a: C \\rightarrow L$ replaced by $a: KC \\rightarrow KL$ and $a: \\neg K \\neg C \\rightarrow \\neg K \\neg L$.\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Loading a blocks instance"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "import tarski.evaluators\n",
    "from tarski.grounding.lp_grounding import LPGroundingStrategy\n",
    "from tarski.theories import Theory\n",
    "from tarski.syntax import *\n",
    "from tarski.io import PDDLReader\n",
    "\n",
    "reader = PDDLReader(raise_on_error=True)\n",
    "reader.parse_domain('./benchmarks/blocksworld.pddl')\n",
    "problem = reader.parse_instance('./benchmarks/probBLOCKS-4-2.pddl')\n",
    "lang = problem.language\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "We will need to ground actions and state variables:"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "grounder = LPGroundingStrategy(problem)\n",
    "actions =  grounder.ground_actions()\n",
    "lpvariables = grounder.ground_state_variables()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Constructing the fluent set $F'$\n",
    "\n",
    "To construct the set of fluents $F'$ we need to create a fresh first-order language\n",
    "to accomodate the new symbols"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "kp_lang = tarski.language(\"K0(P)\", theories=[Theory.EQUALITY])"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "In this tutorial we will explore a compact encoding enabled by the modeling capabilities\n",
    "of Tarski. We start creating a sort (type) for the literals of each of the atoms\n",
    "in the original conformant problem $P$. We call this type `P-literals`"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "p_lits = kp_lang.sort(\"P-literals\", kp_lang.Object)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    " \n",
    "Now we enumerate the atoms in $F$ and we keep matching lists `P_lits` and `reified_P_lits`\n",
    "that will facilitate later the compilation process"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "P_lits = []\n",
    "reified_P_lits = []\n",
    "for atom_index, atoms in lpvariables.enumerate():\n",
    "    f_atom = Atom(atoms.symbol, atoms.binding)\n",
    "    fp_lit = f_atom\n",
    "    fn_lit = neg(f_atom)\n",
    "    P_lits += [fp_lit, fn_lit]\n",
    "    reified_P_lits += [kp_lang.constant(str(fp_lit), p_lits), kp_lang.constant(str(fn_lit), p_lits)]"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "so we end up, for every pair of literals $L$, $\\neg L$, with _objects_ \"$L$\" and\n",
    "\"$\\neg l$\". To obtain $F'$ we need to add a new predicate"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "K = kp_lang.predicate(\"K\", p_lits)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "from which we can easily define the $KL$, $K \\neg L$, $\\neg K L$ \n",
    "and $\\neg K \\neg L$ literals"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "K(reified_P_lits[0])"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "neg(K(reified_P_lits[0]))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "K(reified_P_lits[1])"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "neg(K(reified_P_lits[1]))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Excursion: Inspecting grounded initial states\n",
    "\n",
    "We go on a little excursion to show how we can enumerate the literals that\n",
    "are true in the initial state of a grounded STRIPS problem. First, we need\n",
    "to select what algorithm we want to use to evaluate expressions"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "reader.problem.init.evaluator = tarski.evaluators.simple.evaluate"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "The `simple` evaluator is a straightforward depth-first traversal that processes \n",
    " each of the nodes of the tree formed by the syntactic elements of the expression \n",
    " to be evaluated, returning either a expression or a value.\n",
    "\n",
    "Once the evaluator algorithm is selected, we can use the random access iterator\n",
    "to evaluate expressions as we do below"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "I = []\n",
    "for atom_index, atoms in lpvariables.enumerate():\n",
    "    atom = Atom(atoms.symbol, atoms.binding)\n",
    "    if reader.problem.init[atom]:\n",
    "        I += [atom]\n",
    "    else:\n",
    "        I += [neg(atom)]"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    " to obtain the list of literals true in the initial state."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "for p in I:\n",
    "    print(p)\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Constructing the initial state $I'$\n",
    "\n",
    "For the purpose of this tutorial, we will consider a quite difficult conformant\n",
    "problem, where the only information we have initially is that the robot hand is empty.\n",
    "\n",
    "In order to construct that initial state, we need to access the relevant predicate and\n",
    "object symbols "
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "handempty = reader.problem.language.get('handempty')\n",
    "holding = reader.problem.language.get('holding')\n",
    "a, b, c, d = reader.problem.language.get('a', 'b', 'c', 'd')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "so we can write directly the literals corresponding to the specification above."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "I = [handempty(), neg(holding(a)), neg(holding(b)), neg(holding(c)), neg(holding(d))]"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "We obtain $I'$ by first computing the set of literals of the original conformant\n",
    "problem $P$ that are unit clauses"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "unit_clauses = set()\n",
    "K_I = []\n",
    "for l0 in I:\n",
    "    p_l0 = kp_lang.get(str(l0))\n",
    "    K_I += [K(p_l0)]\n",
    "    unit_clauses.add(symref(l0))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "We use the set `unit_clauses` to then determine which $\\neg K L$ and $\\neg K \\neg L$\n",
    "fluents we need to have in our initial state as well"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "for atom_index, atoms in lpvariables.enumerate():\n",
    "    lp = Atom(atoms.symbol, atoms.binding)\n",
    "    p_lp = kp_lang.get(str(lp))\n",
    "    ln = neg(lp)\n",
    "    p_ln = kp_lang.get(str(ln))\n",
    "    if lp not in unit_clauses:\n",
    "        K_I += [neg(K(p_lp))]\n",
    "    if ln not in unit_clauses:\n",
    "        K_I += [neg(K(p_ln))]"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%    \n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "for k_p in K_I:\n",
    "    print(k_p)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Constructing the goal state $G'$\n",
    "\n",
    "Constructing the goal state proceeds very much as for initial states, but \n",
    "way simpler, as we do not need to complete with the logical implications of\n",
    "literals as we do for initial states"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "on, ontable, clear = reader.problem.language.get('on', 'ontable', 'clear')\n",
    "G = [clear(a), on(a, b), on(b, c), on(c, d), ontable(d)]"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "K_G = []\n",
    "for l_G in G:\n",
    "    p_l_G = kp_lang.get(str(l_G))\n",
    "    K_G += [K(p_l_G)]"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Constructing the action set $O'$\n",
    "\n",
    "Constructing the set of operators is a bit more involved. We start importing\n",
    "a helper function, `ground_schema`, that instantiates action schemas as per the\n",
    "given variable binding."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "from tarski.syntax.transform.action_grounding import ground_schema"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "We use the same interface discussed above, to get access to the set of bindings\n",
    "identified by the grounding procedure, and just call the helper function on the\n",
    "schemata and the bindings."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "O = []\n",
    "for name, ops in actions.items():\n",
    "    print('Action schema', name, 'got', len(ops), 'ground actions')\n",
    "    schema = reader.problem.get_action(name)\n",
    "    print(list(schema.parameters.vars()))\n",
    "    for op in ops:\n",
    "        ground_action = ground_schema(schema, op)\n",
    "        O += [ground_action]\n",
    "        print(ground_action)\n",
    "        print(ground_action.precondition, ground_action.effects)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Creating the precondition and effect formulas of the operators in $O'$ requires\n",
    "1) creating copies of a ground operator, 2) substitute formulas (i.e. wherever\n",
    "it says $L$ it needs to say $KL$) and 3) create new add and del effects for the\n",
    "new operators. "
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "import copy\n",
    "from tarski.syntax.transform.substitutions import substitute_expression\n",
    "from tarski.fstrips import Action, AddEffect, DelEffect"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "We start creating a dictionary where we map literals $L$ to their corresponding\n",
    "$K$-literal"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "subst = {}\n",
    "for p, Kp in zip(P_lits, [K(p) for p in reified_P_lits]):\n",
    "    subst[symref(p)] = Kp"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "note the role played by the two lists `P_lits` and `reified_P_lits` we created\n",
    "above.\n",
    "\n",
    "We note that any effect, the construction of the $KC$ and $KL$ **formulas** \n",
    "is always the same, so we introduce a function that does the translation"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "def make_K_condition_and_effect(subst, eff, K_prec):\n",
    "    KC = [K_prec]\n",
    "    if not isinstance(eff.condition, Tautology):\n",
    "        KC += [substitute_expression(eff.condition, subst)]\n",
    "    KC = land(*KC)\n",
    "    KL = subst[symref(eff.atom)]\n",
    "    KnL = subst[symref(neg(eff.atom))]\n",
    "    \n",
    "    return KC, KL, KnL"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "We finally put together the substitution rule for the $P$-literals, and construct\n",
    "the new set of operators as follows"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "K_O = []\n",
    "for op in O:\n",
    "    K_prec = substitute_expression(op.precondition, subst)\n",
    "    K_effs = []\n",
    "    for eff in op.effects:\n",
    "        KC, KL, KnL = make_K_condition_and_effect(subst, eff, K_prec)\n",
    "        if isinstance(eff, AddEffect):\n",
    "            K_effs += [AddEffect(KC, KL)]\n",
    "            K_effs += [DelEffect(KC, KnL)]\n",
    "        elif isinstance(eff, DelEffect):\n",
    "            K_effs += [DelEffect(KC, KL)]\n",
    "            K_effs += [AddEffect(KC, KnL)]\n",
    "        else:\n",
    "            raise RuntimeError(\"Effect type not supported by compilation!\")\n",
    "    K_O += [Action(kp_lang, op.name, VariableBinding(), K_prec, K_effs)]\n",
    "        \n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "name": "python3",
   "language": "python",
   "display_name": "Python 3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}